{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 802 Project: Genre recognition using FMA\n",
    "Kevin McMahon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('fma_metadata/tracks.csv')\n",
    "genres = pd.read_csv('fma_metadata/genres.csv')\n",
    "echonest = pd.read_csv('fma_metadata/echonest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echonest.shape, genres.shape, tracks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genres\n",
    "Create DataFrame consisting of #tracks and genre_id for the 8 most popular top level genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genres = genres.loc[genres['parent'] == 0]\n",
    "genres = genres.rename(columns={genres.columns[0]: 'Genre id'})\n",
    "genres.index = genres['Genre id']\n",
    "base_genres = genres.drop(columns=['Genre id', 'parent', 'top_level'])\n",
    "base_genres = base_genres.sort_values('#tracks', ascending = False)[:8]\n",
    "\n",
    "\n",
    "# def f(dat, c='red'):\n",
    "#     return [f'background-color: {c}' for i in dat]\n",
    "\n",
    "# df.style.apply(f, axis=0, subset=['X'])\n",
    "\n",
    "colors_list = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'white']\n",
    "\n",
    "base_genres['Color'] = colors_list\n",
    "\n",
    "def color_cols(s):\n",
    "    return [f'background-color: {i}' if colors_list == list(s.values) else '' for i in colors_list]\n",
    "\n",
    "print(f'{8} Most popular top-level genres')\n",
    "base_genres.style.apply(color_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracks\n",
    "1. Remove first 2 rows of header info\n",
    "2. Change 'track.8' genre tags from string to list\n",
    "3. Index the resulting dataframe by track number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracks[2:]\n",
    "tracks['track.8'] = tracks['track.8'].transform(lambda x: x.strip('[]').replace(' ','').split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Make dataframe index the track number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracks.rename(columns={tracks.columns[0]: 'Track number'})\n",
    "tracks.index = tracks['Track number']\n",
    "tracks = tracks.drop(columns=['Track number'])\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echonest\n",
    "1. Eliminate first 3 rows of headers\n",
    "2. Remove features from echonest that are NaN or string (artist, release date, etc)\n",
    "3. Index the resulting dataframe by track number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "echonest = echonest[3:]\n",
    "echonest = echonest.drop(echonest.columns[9:21],axis=1);\n",
    "echonest = echonest.rename(columns={echonest.columns[0]: 'Track number'})\n",
    "echonest.index = echonest['Track number']\n",
    "echonest = echonest.drop(columns=['Track number'])\n",
    "echonest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "echonest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get samples from 8 base genres\n",
    "- Additionally, create a dict that maps a track_id to it's top genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_obtain = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_space = pd.DataFrame(columns=echonest.columns)\n",
    "genre_of_track = dict()\n",
    "\n",
    "genre_map = tracks['track.8']\n",
    "top_level_genres = list(base_genres.index.values)\n",
    "num_samples = 1\n",
    "\n",
    "# Get samples whose genre is one of the 8 base genres\n",
    "for track_id, features in echonest.iterrows():\n",
    "    try:\n",
    "        track_genres = genre_map.loc[track_id]\n",
    "        for gen in track_genres:\n",
    "            if int(gen) in top_level_genres:\n",
    "                feature_space.loc[track_id] = features\n",
    "                genre_of_track[track_id] = int(gen)\n",
    "                num_samples += 1\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if num_samples > samples_to_obtain:\n",
    "        break\n",
    "\n",
    "# Dictionary, maps track_id to genre_id\n",
    "genre_of_track\n",
    "\n",
    "# DataFrame of features for each track\n",
    "feature_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection: Variance Threshold\n",
    "- Remove features below a specified variance\n",
    "- Observe relationship between features retained and threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold = []\n",
    "num_features = []\n",
    "var_range = np.linspace(0, 200, 300)\n",
    "for var in var_range:\n",
    "    vt = VarianceThreshold(var)\n",
    "    selected = vt.fit_transform(feature_space)\n",
    "    num_features.append(len(selected[0]))\n",
    "    threshold.append(var)\n",
    "plt.plot(threshold, num_features)\n",
    "plt.title(f'Number of features vs. Variance Threshold, $n = {len(feature_space)}$')\n",
    "plt.xlabel('Variance Threshold')\n",
    "plt.ylabel('# features selected');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction: PCA\n",
    "- Use PCA to project features to 3D scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_data = pca.fit_transform(normalize(feature_space))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "genre_color_map = {\n",
    "    38: 'b',\n",
    "    15: 'g',\n",
    "    12: 'r',\n",
    "    1235: 'c',\n",
    "    10: 'm',\n",
    "    17: 'y',\n",
    "    21: 'k',\n",
    "    2: 'w'\n",
    "}\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "Z=[]\n",
    "colors=[]\n",
    "for index, sample in enumerate(pca_data):\n",
    "    # Add info to appropriate lists\n",
    "    X.append(sample[0])\n",
    "    Y.append(sample[1])\n",
    "    Z.append(sample[2])\n",
    "    \n",
    "    gen = genre_of_track[feature_space.index.values[index]]\n",
    "    colors.append(genre_color_map[gen])\n",
    "\n",
    "ax.scatter(X,Y,Z, c=colors, alpha=0.5)\n",
    "    \n",
    "# Optionally project plot onto each axis, only useful for n < 10\n",
    "# ax.scatter(X, Z, marker='>', c=colors, zdir='y')\n",
    "# ax.scatter(Y, Z, marker='^', c=colors, zdir='x')\n",
    "# ax.scatter(X, Y, marker='<', c=colors, zdir='z')\n",
    "    \n",
    "ax.set_title(f'PCA for feature space, $n = {len(feature_space)}$')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$z$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class/genre labels for each sample\n",
    "track_genres = []\n",
    "for track_id in list(feature_space.index.values):\n",
    "    track_genres.append(genre_of_track[track_id])\n",
    "\n",
    "lda = LDA(n_components=3)\n",
    "lda_data = lda.fit_transform(feature_space, track_genres)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "Z=[]\n",
    "colors=[]\n",
    "for index, sample in enumerate(lda_data):\n",
    "    # Add info to appropriate lists\n",
    "    X.append(sample[0])\n",
    "    Y.append(sample[1])\n",
    "    Z.append(sample[2])\n",
    "    gen = genre_of_track[feature_space.index.values[index]]\n",
    "    colors.append(genre_color_map[gen])\n",
    "\n",
    "ax.scatter(X,Y,Z, c=colors, alpha=0.5)\n",
    "ax.set_title(f'LDA for feature space, $n = {len(feature_space)}$')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$z$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: LDA with SelectKBest\n",
    "- Select the k 'best' features from the feature space\n",
    "- Scale features space so features can never be negative\n",
    "- Perform LDA and plot results, compare to LDA without selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify value of $d$ (dimensions) and number of features to select before performing LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be greater than dimensions\n",
    "features_to_select = 150\n",
    "\n",
    "# Number of dimensions to reduce LDA \n",
    "# Max value is 237\n",
    "dimensions = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class/genre labels for each sample\n",
    "track_genres = []\n",
    "for track_id in list(feature_space.index.values):\n",
    "    track_genres.append(genre_of_track[track_id])\n",
    "    \n",
    "# Scale so inputs to .fit() functions are not negative\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0,5))\n",
    "scaled_feature_space = min_max_scaler.fit_transform(feature_space)\n",
    "\n",
    "# K Best feature selection\n",
    "kbest_features = SelectKBest(chi2, k=features_to_select).fit_transform(scaled_feature_space, track_genres)\n",
    "\n",
    "# Now use LDA to show effect of selection\n",
    "# Include kbest_features to apply selection to LDA\n",
    "lda_plot = LDA(n_components=3)\n",
    "lda_data_plot = lda_plot.fit_transform(kbest_features, track_genres)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "Z=[]\n",
    "colors=[]\n",
    "for index, sample in enumerate(lda_data_plot):\n",
    "    # Add info to appropriate lists\n",
    "    X.append(sample[0])\n",
    "    Y.append(sample[1])\n",
    "    Z.append(sample[2])\n",
    "    gen = genre_of_track[feature_space.index.values[index]]\n",
    "    colors.append(genre_color_map[gen])\n",
    "\n",
    "ax.scatter(X,Y,Z, c=colors, alpha=0.5)\n",
    "ax.set_title(f'LDA on {dimensions} Best Features from KBest, $n = {len(feature_space)}$')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$z$')\n",
    "\n",
    "# Now do LDA for the correct number of dimensions\n",
    "lda = LDA(n_components=dimensions)\n",
    "lda_data = lda.fit_transform(kbest_features, track_genres)\n",
    "\n",
    "# Use for this and subsequent classifiers to group samples with their class\n",
    "samples_with_labels = [(lda_data[i], track_genres[i]) for i in range(len(track_genres))]\n",
    "\n",
    "lda_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Classification: MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.covariance import EmpiricalCovariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(data, num_features):\n",
    "    total = np.zeros(num_features, dtype=int)\n",
    "    for sample in data:\n",
    "        total = np.add(total, sample)\n",
    "    return total/(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cov(data, num_features, mean):\n",
    "    total = np.zeros((num_features,num_features), dtype=int)\n",
    "    for sample in data:\n",
    "        term1=np.subtract([sample], [mean])\n",
    "        term2=np.subtract([sample], [mean]).transpose()\n",
    "        mult=np.multiply(term1, term2)\n",
    "        total=np.add(total, mult)\n",
    "    return total/(len(data)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "folds = kf.split(samples_with_labels)\n",
    "error_rates = []\n",
    "for train, test in folds:\n",
    "    train_features = [samples_with_labels[i][0] for i in train]\n",
    "    train_classes = [samples_with_labels[i][1] for i in train]\n",
    "    test_features = [samples_with_labels[i][0] for i in test]\n",
    "    test_classes = [samples_with_labels[i][1] for i in test]\n",
    "\n",
    "    # \n",
    "    # Train\n",
    "    # \n",
    "\n",
    "    sigma = []\n",
    "    mu = []\n",
    "    train_dict = dict()\n",
    "\n",
    "    for index in range(len(train_classes)):\n",
    "        features = train_features[index]\n",
    "        sample_class = train_classes[index]\n",
    "\n",
    "        if sample_class not in train_dict:\n",
    "            train_dict[sample_class] = []\n",
    "        train_dict[sample_class].append(features)\n",
    "\n",
    "    for genre_id, samples in train_dict.items():\n",
    "        mu_i = compute_mean(samples, dimensions)\n",
    "        sigma_i = compute_cov(samples, dimensions, mu_i)\n",
    "        sigma.append(sigma_i)\n",
    "        mu.append(mu_i)\n",
    "\n",
    "    # \n",
    "    # Test\n",
    "    # \n",
    "\n",
    "    # Initialize confusion matrix\n",
    "    gen_list = []\n",
    "    for g in list(base_genres.title):\n",
    "        gen_list.append(g[:3])\n",
    "\n",
    "    confusion = pd.DataFrame(0, index=gen_list, columns=gen_list)\n",
    "    confusion = confusion.rename_axis('Actual')\n",
    "    confusion = confusion.rename_axis('Predicted',axis='columns')\n",
    "\n",
    "    # Iterate over the testing set\n",
    "    for testing_index in range(len(test_classes)):\n",
    "        features = test_features[testing_index]\n",
    "        true_class = test_classes[testing_index]\n",
    "\n",
    "        # Calculate class conditional density of each class for each sample\n",
    "        class_cond = []\n",
    "        for class_index, mu_i in enumerate(mu):\n",
    "            sigma_i = sigma[class_index]\n",
    "            rv = mvn(mean=mu_i, cov=sigma_i, allow_singular=True)\n",
    "            class_cond.append(rv.pdf(features))\n",
    "\n",
    "        # Add sample to confusion matrix\n",
    "        j = np.argmax(class_cond)\n",
    "        pred_class = list(train_dict.keys())[j]\n",
    "        true_genre = base_genres.loc[true_class].title[:3]\n",
    "        pred_genre = base_genres.loc[pred_class].title[:3]\n",
    "        confusion.loc[true_genre].loc[pred_genre] += 1\n",
    "\n",
    "    # Display results\n",
    "    correct = sum(confusion.loc[i].loc[i] for i in gen_list)\n",
    "    num_samples = len(test_features)\n",
    "    err = (num_samples-correct)/num_samples*100\n",
    "    error_rates.append(err)\n",
    "    \n",
    "print(f'Average error rate: {np.mean(error_rates)}%')\n",
    "print(f'Variance: {np.var(error_rate)}')\n",
    "print(f'Standard deviation: {np.std(error_rate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k_range = range(2,200,2)\n",
    "err = []\n",
    "min_confusion_matrix = []\n",
    "min_error = 100.0\n",
    "for k in k_range:\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    folds = kf.split(samples_with_labels)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    error_rate = []\n",
    "    for train, test in folds:\n",
    "        train_features = [samples_with_labels[i][0] for i in train]\n",
    "        train_classes = [samples_with_labels[i][1] for i in train]\n",
    "        test_features = [samples_with_labels[i][0] for i in test]\n",
    "        test_classes = [samples_with_labels[i][1] for i in test]\n",
    "\n",
    "        knn.fit(train_features, train_classes)\n",
    "\n",
    "        predicted = knn.predict(test_features)\n",
    "\n",
    "        cm = confusion_matrix(test_classes, predicted)\n",
    "        error = (1-accuracy_score(test_classes, predicted))*100\n",
    "        error_rate.append(error)\n",
    "        \n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            min_confusion_matrix = [cm, k]\n",
    "        \n",
    "    error = np.mean(error_rate)\n",
    "    err.append(error)\n",
    "    # print(f'Error rate for {splits} folds, k = {k}: {error}%')\n",
    "plt.plot(k_range, err)\n",
    "plt.title(f'k-NN error rate vs. k, $n = {len(track_genres)}$')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Error rate, %');\n",
    "\n",
    "print(f'Minimum classification error occured when k = {min_confusion_matrix[1]}\\n')\n",
    "print(f'Error rate: {np.mean(error_rate)}%\\n')\n",
    "print(f'Confusion Matrix:\\n{min_confusion_matrix[0]}\\n')\n",
    "print(f'Variance: {np.var(error_rate)}')\n",
    "print(f'Standard deviation: {np.std(error_rate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "folds = kf.split(samples_with_labels)\n",
    "\n",
    "error_rate = []\n",
    "\n",
    "for index, splits in enumerate(folds):\n",
    "    train, test = splits\n",
    "    train_features = [samples_with_labels[i][0] for i in train]\n",
    "    train_classes = [samples_with_labels[i][1] for i in train]\n",
    "    test_features = [samples_with_labels[i][0] for i in test]\n",
    "    test_classes = [samples_with_labels[i][1] for i in test]\n",
    "    \n",
    "    # set 15% of training data for validation\n",
    "    mlp = MLPClassifier(max_iter = 500, early_stopping=True, validation_fraction=0.15)\n",
    "    mlp.fit(train_features, train_classes)\n",
    "\n",
    "    predicted = mlp.predict(test_features)\n",
    "\n",
    "    cm = confusion_matrix(test_classes, predicted)\n",
    "    error = (1-accuracy_score(test_classes, predicted))*100\n",
    "    error_rate.append(error)\n",
    "    \n",
    "print(f'Average error rate: {np.mean(error_rate)}%')\n",
    "print(f'Variance: {np.var(error_rate)}')\n",
    "print(f'Standard deviation: {np.std(error_rate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "folds = kf.split(samples_with_labels)\n",
    "\n",
    "error_rate = []\n",
    "\n",
    "for index, splits in enumerate(folds):\n",
    "    train, test = splits\n",
    "    train_features = [samples_with_labels[i][0] for i in train]\n",
    "    train_classes = [samples_with_labels[i][1] for i in train]\n",
    "    test_features = [samples_with_labels[i][0] for i in test]\n",
    "    test_classes = [samples_with_labels[i][1] for i in test]\n",
    "    \n",
    "    clf = SVC()\n",
    "    mlp.fit(train_features, train_classes)\n",
    "\n",
    "    predicted = mlp.predict(test_features)\n",
    "\n",
    "    cm = confusion_matrix(test_classes, predicted)\n",
    "    error = (1-accuracy_score(test_classes, predicted))*100\n",
    "    error_rate.append(error)\n",
    "    \n",
    "print(f'Average error rate: {np.mean(error_rate)}%')\n",
    "print(f'Variance: {np.var(error_rate)}')\n",
    "print(f'Standard deviation: {np.std(error_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
